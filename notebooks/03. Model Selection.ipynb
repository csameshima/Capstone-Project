{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "## Objective\n",
    "\n",
    "The purpose of this notebook is to test different models for the project.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Define data file\n",
    "file ='../dataset/ObesityDataSet_raw_and_data_sinthetic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Load dataset to a pandas dataframe for analysis\n",
    "ds = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of binary data\n",
    "ds[\"Gender\"] = ds.Gender.apply(lambda s: 1 if s == \"Female\" else 0)\n",
    "ds[\"family_history_with_overweight\"] = ds.family_history_with_overweight.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "ds[\"FAVC\"] = ds.FAVC.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "ds[\"SMOKE\"] = ds.SMOKE.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "ds[\"SCC\"] = ds.SCC.apply(lambda s: 1 if s == \"yes\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for categorical data\n",
    "CAEC_list = pd.get_dummies(ds.CAEC, prefix=\"CAEC\")\n",
    "ds.drop(\"CAEC\", inplace=True, axis=1)\n",
    "ds = ds.join(CAEC_list)\n",
    "\n",
    "CALC_list = pd.get_dummies(ds.CALC, prefix=\"CALC\")\n",
    "ds.drop(\"CALC\", inplace=True, axis=1)\n",
    "ds = ds.join(CALC_list)\n",
    "\n",
    "MTRANS_list = pd.get_dummies(ds.MTRANS, prefix=\"MTRANS\")\n",
    "ds.drop(\"MTRANS\", inplace=True, axis=1)\n",
    "ds = ds.join(MTRANS_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of target feature through a dictionary\n",
    "obesity = {\"Insufficient_Weight\":1, \"Normal_Weight\":2, \"Overweight_Level_I\":3, \"Overweight_Level_II\":4, \"Obesity_Type_I\":5, \"Obesity_Type_II\":6, \"Obesity_Type_III\":7}\n",
    "ds[\"NObeyesdad\"] = ds.NObeyesdad.map(obesity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Train and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(ds.drop('NObeyesdad',axis=1), \n",
    "                                                    ds['NObeyesdad'],\n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "log_model = LogisticRegression(max_iter=10000)\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8911671924290221"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model\n",
    "y_pred = log_model.predict(X_test)\n",
    "log_accuracy = accuracy_score (y_test, y_pred)\n",
    "log_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.96      0.92        90\n",
      "           2       0.85      0.78      0.81        87\n",
      "           3       0.82      0.77      0.79        81\n",
      "           4       0.81      0.80      0.81        82\n",
      "           5       0.93      0.90      0.92       103\n",
      "           6       0.95      1.00      0.97        90\n",
      "           7       0.94      0.99      0.97       101\n",
      "\n",
      "    accuracy                           0.89       634\n",
      "   macro avg       0.89      0.89      0.88       634\n",
      "weighted avg       0.89      0.89      0.89       634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 86,   4,   0,   0,   0,   0,   0],\n",
       "       [ 10,  68,   7,   2,   0,   0,   0],\n",
       "       [  0,   8,  62,  11,   0,   0,   0],\n",
       "       [  0,   0,   7,  66,   7,   1,   1],\n",
       "       [  0,   0,   0,   2,  93,   3,   5],\n",
       "       [  0,   0,   0,   0,   0,  90,   0],\n",
       "       [  0,   0,   0,   0,   0,   1, 100]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8564668769716088"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model\n",
    "y_pred = svm_model.predict(X_test)\n",
    "svm_accuracy = accuracy_score (y_test, y_pred)\n",
    "svm_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.92      0.91        90\n",
      "           2       0.63      0.71      0.67        87\n",
      "           3       0.81      0.77      0.78        81\n",
      "           4       0.76      0.73      0.75        82\n",
      "           5       0.92      0.84      0.88       103\n",
      "           6       0.97      0.99      0.98        90\n",
      "           7       1.00      0.99      1.00       101\n",
      "\n",
      "    accuracy                           0.86       634\n",
      "   macro avg       0.85      0.85      0.85       634\n",
      "weighted avg       0.86      0.86      0.86       634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 83,   7,   0,   0,   0,   0,   0],\n",
       "       [  8,  62,   8,   9,   0,   0,   0],\n",
       "       [  0,  13,  62,   4,   2,   0,   0],\n",
       "       [  1,   9,   7,  60,   5,   0,   0],\n",
       "       [  0,   7,   0,   6,  87,   3,   0],\n",
       "       [  0,   0,   0,   0,   1,  89,   0],\n",
       "       [  0,   1,   0,   0,   0,   0, 100]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8123028391167192"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model\n",
    "y_pred = knn_model.predict(X_test)\n",
    "knn_accuracy = accuracy_score (y_test, y_pred)\n",
    "knn_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.93      0.86        90\n",
      "           2       0.63      0.49      0.55        87\n",
      "           3       0.77      0.72      0.74        81\n",
      "           4       0.70      0.76      0.73        82\n",
      "           5       0.84      0.79      0.81       103\n",
      "           6       0.89      0.97      0.93        90\n",
      "           7       0.98      0.99      0.99       101\n",
      "\n",
      "    accuracy                           0.81       634\n",
      "   macro avg       0.80      0.81      0.80       634\n",
      "weighted avg       0.81      0.81      0.81       634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 84,   4,   1,   1,   0,   0,   0],\n",
       "       [ 17,  43,  10,  11,   4,   2,   0],\n",
       "       [  1,   9,  58,   4,   7,   2,   0],\n",
       "       [  1,   7,   4,  62,   4,   4,   0],\n",
       "       [  3,   5,   1,   9,  81,   2,   2],\n",
       "       [  0,   0,   1,   1,   1,  87,   0],\n",
       "       [  0,   0,   0,   0,   0,   1, 100]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5473186119873817"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model\n",
    "y_pred = gnb_model.predict(X_test)\n",
    "gnb_accuracy = accuracy_score (y_test, y_pred)\n",
    "gnb_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.97      0.47        90\n",
      "           2       0.68      0.22      0.33        87\n",
      "           3       0.58      0.14      0.22        81\n",
      "           4       0.53      0.10      0.16        82\n",
      "           5       0.61      0.45      0.51       103\n",
      "           6       0.68      0.84      0.75        90\n",
      "           7       0.99      0.99      0.99       101\n",
      "\n",
      "    accuracy                           0.55       634\n",
      "   macro avg       0.62      0.53      0.49       634\n",
      "weighted avg       0.63      0.55      0.51       634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 87,   3,   0,   0,   0,   0,   0],\n",
       "       [ 61,  19,   6,   1,   0,   0,   0],\n",
       "       [ 61,   3,  11,   3,   3,   0,   0],\n",
       "       [ 44,   2,   2,   8,  13,  13,   0],\n",
       "       [ 30,   1,   0,   2,  46,  23,   1],\n",
       "       [  0,   0,   0,   1,  13,  76,   0],\n",
       "       [  0,   0,   0,   0,   1,   0, 100]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9321766561514195"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model\n",
    "y_pred = tree_model.predict(X_test)\n",
    "tree_accuracy = accuracy_score (y_test, y_pred)\n",
    "tree_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.92      0.96      0.94        90\n",
      "           2       0.89      0.82      0.85        87\n",
      "           3       0.87      0.85      0.86        81\n",
      "           4       0.89      0.93      0.91        82\n",
      "           5       0.95      0.97      0.96       103\n",
      "           6       0.99      0.99      0.99        90\n",
      "           7       0.98      0.99      0.99       101\n",
      "\n",
      "    accuracy                           0.93       634\n",
      "   macro avg       0.93      0.93      0.93       634\n",
      "weighted avg       0.93      0.93      0.93       634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 86,   4,   0,   0,   0,   0,   0],\n",
       "       [  7,  71,   8,   1,   0,   0,   0],\n",
       "       [  0,   5,  69,   7,   0,   0,   0],\n",
       "       [  0,   0,   2,  76,   4,   0,   0],\n",
       "       [  0,   0,   0,   1, 100,   0,   2],\n",
       "       [  0,   0,   0,   0,   1,  89,   0],\n",
       "       [  0,   0,   0,   0,   0,   1, 100]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:   0.8911671924290221\n",
      "SVM:                   0.8564668769716088\n",
      "KNN:                   0.8123028391167192\n",
      "Gaussian Naive Bayes:  0.5473186119873817\n",
      "Decision Trees:        0.9321766561514195\n"
     ]
    }
   ],
   "source": [
    "print (\"Logistic Regression:  \", log_accuracy)\n",
    "print (\"SVM:                  \", svm_accuracy)\n",
    "print (\"KNN:                  \", knn_accuracy)\n",
    "print (\"Gaussian Naive Bayes: \", gnb_accuracy)\n",
    "print (\"Decision Trees:       \", tree_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
