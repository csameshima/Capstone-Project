{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Htperparameter Testing\n",
    "\n",
    "## Objective\n",
    "\n",
    "The purpose of this notebook is to perform a preliminary hyperparameter testing for the project.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Define data file\n",
    "file ='../dataset/ObesityDataSet_raw_and_data_sinthetic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Load dataset to a pandas dataframe for analysis\n",
    "ds = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of binary data\n",
    "ds[\"Gender\"] = ds.Gender.apply(lambda s: 1 if s == \"Female\" else 0)\n",
    "ds[\"family_history_with_overweight\"] = ds.family_history_with_overweight.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "ds[\"FAVC\"] = ds.FAVC.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "ds[\"SMOKE\"] = ds.SMOKE.apply(lambda s: 1 if s == \"yes\" else 0)\n",
    "ds[\"SCC\"] = ds.SCC.apply(lambda s: 1 if s == \"yes\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for categorical data\n",
    "CAEC_list = pd.get_dummies(ds.CAEC, prefix=\"CAEC\")\n",
    "ds.drop(\"CAEC\", inplace=True, axis=1)\n",
    "ds = ds.join(CAEC_list)\n",
    "\n",
    "CALC_list = pd.get_dummies(ds.CALC, prefix=\"CALC\")\n",
    "ds.drop(\"CALC\", inplace=True, axis=1)\n",
    "ds = ds.join(CALC_list)\n",
    "\n",
    "MTRANS_list = pd.get_dummies(ds.MTRANS, prefix=\"MTRANS\")\n",
    "ds.drop(\"MTRANS\", inplace=True, axis=1)\n",
    "ds = ds.join(MTRANS_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of target feature through a dictionary\n",
    "obesity = {\"Insufficient_Weight\":1, \"Normal_Weight\":2, \"Overweight_Level_I\":3, \"Overweight_Level_II\":4, \"Obesity_Type_I\":5, \"Obesity_Type_II\":6, \"Obesity_Type_III\":7}\n",
    "ds[\"NObeyesdad\"] = ds.NObeyesdad.map(obesity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Train and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(ds.drop('NObeyesdad',axis=1), \n",
    "                                                    ds['NObeyesdad'],\n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "The hyperparameters to test are:\n",
    "* Maximum depth of the tree (max_depth).  \n",
    "* Minimum number of samples required to split (min_samples_split).  \n",
    "\n",
    "**Maximum depth.**  \n",
    "This is the maximum depth of the tree.  \n",
    "The default value is *None*.  \n",
    "A high value causes overfitting. A low value causes underfitting.  \n",
    "The values selected for the pre-test were 5, 10, 50, 100 to test underfitting and overfitting.  \n",
    "\n",
    "**Minimum number of samples.**  \n",
    "This is the minimum number of samples required to split an internal node.  \n",
    "The default value is 2.  \n",
    "The values selected for the sampler were 2, 10, 50, 100 to see the effect of the selecting too few an too many samples.  \n",
    "\n",
    "**Note:** *random_state* was set to 0, to obtain a deterministic behaviour during fitting.  \n",
    "This parameter controls the randomness of the estimator. If set to the default value *None*, the features are randomly permuted at each split. The best found split may vary across different runs.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=100, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train models\n",
    "model_none = tree.DecisionTreeClassifier(max_depth = None, random_state = 0)\n",
    "model_none.fit(X_train, y_train)\n",
    "model_5 = tree.DecisionTreeClassifier(max_depth = 5, random_state = 0)\n",
    "model_5.fit(X_train, y_train)\n",
    "model_10 = tree.DecisionTreeClassifier(max_depth = 10, random_state = 0)\n",
    "model_10.fit(X_train, y_train)\n",
    "model_50 = tree.DecisionTreeClassifier(max_depth = 50, random_state = 0)\n",
    "model_50.fit(X_train, y_train)\n",
    "model_100 = tree.DecisionTreeClassifier(max_depth = 100, random_state = 0)\n",
    "model_100.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test models\n",
    "y_pred_none = model_none.predict(X_test)\n",
    "accuracy_none = accuracy_score (y_test, y_pred_none)\n",
    "y_pred_5 = model_5.predict(X_test)\n",
    "accuracy_5 = accuracy_score (y_test, y_pred_5)\n",
    "y_pred_10 = model_10.predict(X_test)\n",
    "accuracy_10 = accuracy_score (y_test, y_pred_10)\n",
    "y_pred_50 = model_50.predict(X_test)\n",
    "accuracy_50 = accuracy_score (y_test, y_pred_50)\n",
    "y_pred_100 = model_100.predict(X_test)\n",
    "accuracy_100 = accuracy_score (y_test, y_pred_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None:   0.9321766561514195\n",
      "5:      0.832807570977918\n",
      "10:     0.9337539432176656\n",
      "50:     0.9321766561514195\n",
      "100:    0.9321766561514195\n"
     ]
    }
   ],
   "source": [
    "print (\"None:  \", accuracy_none)\n",
    "print (\"5:     \", accuracy_5)\n",
    "print (\"10:    \", accuracy_10)\n",
    "print (\"50:    \", accuracy_50)\n",
    "print (\"100:   \", accuracy_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameter is a tree with a maximum depth of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minumum Number of Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=100,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train models\n",
    "model_2 = tree.DecisionTreeClassifier(min_samples_split = 2, random_state = 0)\n",
    "model_2.fit(X_train, y_train)\n",
    "model_5 = tree.DecisionTreeClassifier(min_samples_split = 5, random_state = 0)\n",
    "model_5.fit(X_train, y_train)\n",
    "model_10 = tree.DecisionTreeClassifier(min_samples_split = 10, random_state = 0)\n",
    "model_10.fit(X_train, y_train)\n",
    "model_50 = tree.DecisionTreeClassifier(min_samples_split = 50, random_state = 0)\n",
    "model_50.fit(X_train, y_train)\n",
    "model_100 = tree.DecisionTreeClassifier(min_samples_split = 100, random_state = 0)\n",
    "model_100.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test models\n",
    "y_pred_2 = model_2.predict(X_test)\n",
    "accuracy_2 = accuracy_score (y_test, y_pred_2)\n",
    "y_pred_5 = model_5.predict(X_test)\n",
    "accuracy_5 = accuracy_score (y_test, y_pred_5)\n",
    "y_pred_10 = model_10.predict(X_test)\n",
    "accuracy_10 = accuracy_score (y_test, y_pred_10)\n",
    "y_pred_50 = model_50.predict(X_test)\n",
    "accuracy_50 = accuracy_score (y_test, y_pred_50)\n",
    "y_pred_100 = model_100.predict(X_test)\n",
    "accuracy_100 = accuracy_score (y_test, y_pred_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:    0.9321766561514195\n",
      "5:    0.9274447949526814\n",
      "10:   0.9274447949526814\n",
      "50:   0.8943217665615142\n",
      "100:  0.8233438485804416\n"
     ]
    }
   ],
   "source": [
    "print (\"2:   \", accuracy_2)\n",
    "print (\"5:   \", accuracy_5)\n",
    "print (\"10:  \", accuracy_10)\n",
    "print (\"50:  \", accuracy_50)\n",
    "print (\"100: \", accuracy_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameter is a minumum number of samples of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
